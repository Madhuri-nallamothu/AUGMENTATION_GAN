{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLM6o1DSjcXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "#%matplotlib inline\n",
        "import argparse\n",
        "import datetime\n",
        "import os\n",
        "import os.path\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import SubsetRandomSampler\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "from IPython.display import clear_output\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZ7QF4YbN1Pl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "b1cf131e-9bb4-4cca-d763-76b47f24ced8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') \n",
        "%cd /content/drive/My\\ Drive/"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MdEuFt0nkmc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "data_dir = 'div2k' #Jus to check\n",
        "batch_size = 64\n",
        "LOAD_MODEL = True\n",
        "PATH='/content/drive/My Drive/augGAN/model/+5.311_+0.053_300_2020-08-06_18:26:13.dat' \n",
        "TRAIN_ALL = False\n",
        "#All images will be resized to this size using a transformer.\n",
        "image_size = 64\n",
        "\n",
        "# Number of channels in the training images. For color images this is 3\n",
        "nc = 1\n",
        "\n",
        "# Size of z latent vector (i.e. size of generator input)\n",
        "nz = 100\n",
        "\n",
        "# Size of feature maps in generator\n",
        "ngf = 64\n",
        "\n",
        "# Size of feature maps in discriminator\n",
        "ndf = 64\n",
        "\n",
        "# Number of training epochs\n",
        "num_epochs = 300\n",
        "\n",
        "# Learning rate for optimizers\n",
        "lr = 0.0002\n",
        "lr_d = 0.0002\n",
        "# Beta1 hyperparam for Adam optimizers\n",
        "beta1 = 0.5\n",
        "# Beta2 hyperparam for Adam optimizers\n",
        "beta2 = 0.999\n",
        "\n",
        "real_label = 1.\n",
        "fake_label = 0.\n",
        "# Input to generator\n",
        "fixed_noise = torch.randn(64, nz, 1, 1, device=device) #batch of 64\n",
        "# Define Loss function\n",
        "criterion = nn.BCELoss()"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHXGFAtBHH4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4uvXCj5zzNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class Generator(nn.Module):\n",
        "\n",
        "#     def __init__(self):\n",
        "#         super(Generator, self).__init__()\n",
        "#         self._model = nn.Sequential(\n",
        "#             # input is Z, going into a convolution\n",
        "#             #i/p,o/p,kernel size,stride,padding\n",
        "#             nn.ConvTranspose2d( nz, ngf * 16, 4, 1, 0, bias=False),\n",
        "#             nn.BatchNorm2d(ngf * 16),\n",
        "#             nn.ReLU(True),\n",
        "#             # state size. (ngf*16) x 4 x 4\n",
        "#             nn.ConvTranspose2d( ngf * 16, ngf * 8, 4, 2, 1, bias=False),\n",
        "#             nn.BatchNorm2d(ngf * 8),\n",
        "#             nn.ReLU(True),\n",
        "#             # state size. (ngf*8) x 8 x 8\n",
        "#             nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "#             nn.BatchNorm2d(ngf * 4),\n",
        "#             nn.ReLU(True),\n",
        "#             # state size. (ngf*4) x 16 x 16\n",
        "#             nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "#             nn.BatchNorm2d(ngf * 2),\n",
        "#             nn.ReLU(True),\n",
        "#             # state size. (ngf*2) x 32 x 32\n",
        "#             nn.ConvTranspose2d( ngf*2, nc, 4, 2, 1, bias=False),\n",
        "#             nn.Tanh()\n",
        "#             # state size. (nc) x 64 x 64\n",
        "#         )\n",
        "\n",
        "#     def forward(self, input):\n",
        "#         return self._model(input)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            # input is Z, going into a convolution\n",
        "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*4) x 8 x 8\n",
        "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*2) x 16 x 16\n",
        "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf) x 32 x 32\n",
        "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "            # state size. (nc) x 64 x 64\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEb5BlY5GO4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class Discriminator(nn.Module):\n",
        "\n",
        "#     def __init__(self):\n",
        "#         super(Discriminator, self).__init__()\n",
        "#         self._model = nn.Sequential(\n",
        "#             # input is (nc) x 64 x 64\n",
        "#             nn.Conv2d(nc, ndf * 2, 4, 2, 1, bias=False),\n",
        "#             nn.LeakyReLU(0.2, inplace=True),\n",
        "#             # state size. (ndf*2) x 32 x 32\n",
        "#             nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "#             nn.BatchNorm2d(ndf * 4),\n",
        "#             nn.LeakyReLU(0.2, inplace=True),\n",
        "#             # state size. (ndf*4) x 16 x 16\n",
        "#             nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "#             nn.BatchNorm2d(ndf * 8),\n",
        "#             nn.LeakyReLU(0.2, inplace=True),\n",
        "#             # state size. (ndf*8) x 8 x 8\n",
        "#             nn.Conv2d(ndf * 8, ndf * 16, 4, 2, 1, bias=False),\n",
        "#             nn.BatchNorm2d(ndf * 16),\n",
        "#             nn.LeakyReLU(0.2, inplace=True),\n",
        "#             # state size. (ndf*16) x 4 x 4\n",
        "#             nn.Conv2d(ndf * 16, 1, 4, 1, 0, bias=False),\n",
        "#             nn.Sigmoid()\n",
        "#         )\n",
        "\n",
        "#     def forward(self, input):\n",
        "#         return self._model(input)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            # input is (nc) x 64 x 64\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf) x 32 x 32\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*2) x 16 x 16\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*4) x 8 x 8\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*8) x 4 x 4\n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfQtVNCNGIHt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_loss(G_losses, D_losses):\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.title(\"Generator and Discriminator Loss During Training\")\n",
        "    plt.plot(G_losses,label=\"G\")\n",
        "    plt.plot(D_losses,label=\"D\")\n",
        "    plt.xlabel(\"iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVLWLMetCrGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot(name, train_epoch, values, path, save):\n",
        "    clear_output(wait=True)\n",
        "    plt.close('all')\n",
        "    fig = plt.figure()\n",
        "    fig = plt.ion()\n",
        "    fig = plt.subplot(1, 1, 1)\n",
        "    fig = plt.title('epoch: %s -> %s: %s' % (train_epoch, name, values[-1]))\n",
        "    fig = plt.ylabel(name)\n",
        "    fig = plt.xlabel('train_set')\n",
        "    fig = plt.plot(values)\n",
        "    fig = plt.grid()\n",
        "    get_fig = plt.gcf()\n",
        "    fig = plt.draw()  # draw the plot\n",
        "    fig = plt.pause(1)  # show it for 1 second\n",
        "    if save:\n",
        "        now = datetime.datetime.now()\n",
        "        get_fig.savefig('%s/%s_%.3f_%d_%s.png' %\n",
        "                        (path, name, train_epoch, values[-1], now.strftime(\"%Y-%m-%d_%H:%M:%S\")))"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekCtxRmkLl5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def display_real_fake(loader, img_list):\n",
        "    real_batch = next(iter(loader))\n",
        "\n",
        "    # Plot the real images\n",
        "    plt.figure(figsize=(15,15))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Real Images\")\n",
        "    plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
        "\n",
        "    # Plot the fake images from the last epoch\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Fake Images\")\n",
        "    plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
        "    plt.show()"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHGbk-t3imrL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(generator, discriminator, gen_optimizer, dis_optimizer, metrics, num_epochs):\n",
        "    now = datetime.datetime.now()\n",
        "    g_losses = metrics['train.G_losses'][-1]\n",
        "    d_losses = metrics['train.D_losses'][-1]\n",
        "    name = \"%+.3f_%+.3f_%d_%s.dat\" % (g_losses, d_losses, num_epochs, now.strftime(\"%Y-%m-%d_%H:%M:%S\"))\n",
        "    fname = os.path.join('.', 'augGAN/model', name)\n",
        "    states = {\n",
        "            'state_dict_generator': generator.state_dict(),\n",
        "            'state_dict_discriminator': discriminator.state_dict(),\n",
        "            'gen_optimizer': gen_optimizer.state_dict(),\n",
        "            'dis_optimizer': dis_optimizer.state_dict(),\n",
        "            'metrics': metrics,\n",
        "            'train_epoch': num_epochs,\n",
        "            'date': now.strftime(\"%Y-%m-%d_%H:%M:%S\"),\n",
        "    }\n",
        "    torch.save(states, fname)\n",
        "    path='augGAN/plots/train_%+.3f_%+.3f_%s'% (g_losses, d_losses, now.strftime(\"%Y-%m-%d_%H:%M:%S\"))\n",
        "    try:\n",
        "      os.mkdir(os.path.join('.', path))\n",
        "    except Exception as error:\n",
        "      print(error)\n",
        "\n",
        "    plot('G_losses', num_epochs, metrics['train.G_losses'], path, True)\n",
        "    plot('D_losses', num_epochs, metrics['train.D_losses'], path, True)\n",
        "    plot('D_x', num_epochs, metrics['train.D_x'], path, True)\n",
        "    plot('D_G_z1', num_epochs, metrics['train.D_G_z1'], path, True)\n",
        "    plot('D_G_z2', num_epochs, metrics['train.D_G_z2'], path, True)"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xn5d4tccMIyL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "\n",
        "def train_gan(generator, discriminator, gen_optimizer, dis_optimizer, train_loader, valid_loader, num_epochs, metrics):\n",
        "        iters = 0\n",
        "        print(\"GAN training started :D...\")\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print(\"Epoch %d\" %(epoch+1))\n",
        "            # For each batch in the dataloader\n",
        "            for i, data in enumerate(tqdm(train_loader, 0)):\n",
        "                # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "                ## Train with all-real batch\n",
        "                discriminator.zero_grad()\n",
        "                # Format batch\n",
        "                b_real = data[0].to(device)\n",
        "                b_size = b_real.size(0)\n",
        "                label = torch.full((b_size,), real_label, device=device)\n",
        "                # Forward pass real batch through D\n",
        "                output = discriminator(b_real).view(-1)\n",
        "                # Calculate loss on all-real batch\n",
        "                errD_real = criterion(output, label)\n",
        "                # Calculate gradients for D in backward pass\n",
        "                errD_real.backward()\n",
        "                D_x = output.mean().item()\n",
        "                metrics['train.D_x'].append(D_x)\n",
        "\n",
        "                ## Train with all-fake batch\n",
        "                # Generate batch of latent vectors\n",
        "                noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
        "                # Generate fake image batch with G\n",
        "                fake = generator(noise)\n",
        "                label.fill_(fake_label)\n",
        "                # Classify all fake batch with D\n",
        "                output = discriminator(fake.detach()).view(-1)\n",
        "                # Calculate D's loss on the all-fake batch\n",
        "                errD_fake = criterion(output, label)\n",
        "                # Calculate the gradients for this batch\n",
        "                errD_fake.backward()\n",
        "                D_G_z1 = output.mean().item()\n",
        "                metrics['train.D_G_z1'].append(D_G_z1)\n",
        "                # Add the gradients from the all-real and all-fake batches\n",
        "                errD = errD_real + errD_fake\n",
        "                # Update D\n",
        "                dis_optimizer.step()\n",
        "\n",
        "                # (2) Update G network: maximize log(D(G(z)))\n",
        "                generator.zero_grad()\n",
        "                label.fill_(real_label)  # fake labels are real for generator cost\n",
        "                # Since we just updated D, perform another forward pass of all-fake batch through D\n",
        "                output = discriminator(fake).view(-1)\n",
        "                # Calculate G's loss based on this output\n",
        "                errG = criterion(output, label)\n",
        "                # Calculate gradients for G\n",
        "                errG.backward()\n",
        "                D_G_z2 = output.mean().item()\n",
        "                metrics['train.D_G_z2'].append(D_G_z2)\n",
        "                # Update G\n",
        "                gen_optimizer.step()\n",
        "\n",
        "                # Output training stats\n",
        "                #if i % 50 == 0:\n",
        "                #print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                #      % (epoch, num_epochs, i, len(train_loader),\n",
        "                #          errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "\n",
        "                # Save Losses for plotting later\n",
        "                G_losses.append(errG.item())\n",
        "                D_losses.append(errD.item())\n",
        "                metrics['train.G_losses'].append(errG.item())\n",
        "                metrics['train.D_losses'].append(errD.item())\n",
        "\n",
        "                # Check how the generator is doing by saving G's output on fixed_noise\n",
        "                if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(train_loader)-1)):\n",
        "                    with torch.no_grad():\n",
        "                        fake = generator(fixed_noise).detach().cpu()\n",
        "                    img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
        "\n",
        "                iters += 1\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                  % (epoch+1, num_epochs, i, len(train_loader),\n",
        "                    errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "        #plot_loss(G_losses, D_losses)\n",
        "        save_model(generator, discriminator, gen_optimizer, dis_optimizer, metrics, num_epochs)\n",
        "        display_real_fake(train_loader, img_list)"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPHMkQQKJItb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_indices(dataset,class_name, indices):\n",
        "    #indices =  []\n",
        "    j = 0\n",
        "    for i in range(len(dataset.labels)):\n",
        "        if dataset.labels[i] == class_name:\n",
        "            indices.append(i)\n",
        "            j += 1\n",
        "    print(\"Total Samples of class\", class_name,\"found are\",j)\n",
        "    return indices"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncRL2jjtN-Ns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_fake(generator, discriminator, metrics):\n",
        "    now = datetime.datetime.now()\n",
        "    g_losses = metrics['train.G_losses'][-1]\n",
        "    d_losses = metrics['train.D_losses'][-1]\n",
        "    path='augGAN/output_images/%+.3f_%+.3f_%s'% (g_losses, d_losses, now.strftime(\"%Y-%m-%d_%H:%M:%S\"))\n",
        "    try:\n",
        "      os.mkdir(os.path.join('.', path))\n",
        "    except Exception as error:\n",
        "      print(error)\n",
        "\n",
        "    im_batch_size = 20\n",
        "    n_images=100\n",
        "    for i_batch in range(0, n_images, im_batch_size):\n",
        "        gen_z = torch.randn(im_batch_size, 100, 1, 1, device=device)\n",
        "        gen_images = generator(gen_z)\n",
        "        dis_result = discriminator(gen_images).view(-1)\n",
        "        images = gen_images.to(\"cpu\").clone().detach()\n",
        "        images = images.numpy().transpose(0, 2, 3, 1)\n",
        "        for i_image in range(gen_images.size(0)):\n",
        "            save_image(gen_images[i_image, :, :, :], os.path.join(path, f'image_{i_batch+i_image:05d}.png'))\n",
        "\n",
        "    print('Testing Block.........')\n",
        "    print('Discriminator_mean: ', dis_result.mean().item())\n",
        "    #import shutil\n",
        "    #shutil.make_archive('images', 'zip', './augGAN/output_images')"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWeXmdInu38z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "502caa20-054b-406f-b535-2bdbc3d28310"
      },
      "source": [
        "for func in [\n",
        "    lambda: os.mkdir(os.path.join('.', 'augGAN')),\n",
        "    lambda: os.mkdir(os.path.join('.', 'augGAN/model')),\n",
        "    lambda: os.mkdir(os.path.join('.', 'augGAN/plots')),\n",
        "    lambda: os.mkdir(os.path.join('.', 'augGAN/output_images'))]:  # create directories\n",
        "  try:\n",
        "    func()\n",
        "  except Exception as error:\n",
        "    print(error)\n",
        "    continue\n",
        "\n",
        "METRIC_FIELDS = [\n",
        "    'train.D_x',\n",
        "    'train.D_G_z1',\n",
        "    'train.D_G_z2',\n",
        "    'train.G_losses',\n",
        "    'train.D_losses',\n",
        "]\n",
        "metrics = {field: list() for field in METRIC_FIELDS}\n",
        "\n",
        "if nc==1:\n",
        "    mu = (0.5)\n",
        "    sigma = (0.5)\n",
        "    transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
        "                                    transforms.Grayscale(num_output_channels=1),\n",
        "                                    transforms.Resize((64,64)),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize(mu, sigma)])\n",
        "elif nc==3:\n",
        "    mu = (0.5,0.5,0.5)\n",
        "    sigma = (0.5,0.5,0.5)\n",
        "    #Originally authors used just scaling\n",
        "    transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
        "                                    transforms.Resize((64,64)),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize(mu, sigma)])\n",
        "else:\n",
        "    print(\"Tranformation not defined for this option\")\n",
        "#train_set = datasets.ImageFolder(os.path.join(\n",
        "#      data_dir, \"train/\"), transform=transform)\n",
        "train_set = datasets.STL10(root='./data', split='train', download=True,\n",
        "                                transform=transform)\n",
        "#train_loader = torch.utils.data.DataLoader(\n",
        "#      train_set, batch_size=batch_size, shuffle=True)\n",
        "#valid_set = datasets.ImageFolder(os.path.join( \n",
        "#      data_dir, \"val/\"), transform=transform)\n",
        "valid_set = datasets.STL10(root='./data', split='test', download=True,\n",
        "                                transform=transform)\n",
        "valid_loader = torch.utils.data.DataLoader(\n",
        "      valid_set, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "generator.apply(weights_init)\n",
        "discriminator.apply(weights_init)\n",
        "gen_optimizer = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, beta2))\n",
        "dis_optimizer = optim.Adam(discriminator.parameters(), lr=lr_d, betas=(beta1, beta2))\n",
        "\n",
        "if LOAD_MODEL:\n",
        "    if torch.cuda.is_available():\n",
        "      checkpoint = torch.load(PATH)\n",
        "    else:\n",
        "      checkpoint = torch.load(PATH, map_location=lambda storage, loc: storage)\n",
        "              \n",
        "    generator.load_state_dict(checkpoint['state_dict_generator'])\n",
        "    discriminator.load_state_dict(checkpoint['state_dict_discriminator'])\n",
        "    gen_optimizer.load_state_dict(checkpoint['gen_optimizer'])\n",
        "    dis_optimizer.load_state_dict(checkpoint['dis_optimizer'])\n",
        "    metrics=checkpoint['metrics']\n",
        "    num_epochs=checkpoint['train_epoch']\n",
        "    date=checkpoint['date']\n",
        "    generator.train(mode=False)\n",
        "    discriminator.train(mode=False)\n",
        "    print('GAN loaded for epochs: ', num_epochs)\n",
        "    print(generator)\n",
        "    print(discriminator)\n",
        "    print(gen_optimizer)\n",
        "    print(dis_optimizer)\n",
        "    print(date)\n",
        "else:\n",
        "    if TRAIN_ALL:\n",
        "        train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
        "                                                  shuffle=True)\n",
        "        train_gan(generator, discriminator, gen_optimizer, dis_optimizer, train_loader,\n",
        "                  valid_loader, num_epochs, metrics)\n",
        "    else:\n",
        "        idx = []\n",
        "        idx = get_indices(train_set, 0, idx) #Airplane\n",
        "        #idx_2 = get_indices(train_set, 8, idx) #Ship\n",
        "        #idx_3 = get_indices(train_set, 9, idx) #Truck\n",
        "\n",
        "        print(\"Total samples now are \",len(idx))\n",
        "        selected_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
        "                                                      sampler = SubsetRandomSampler(idx))\n",
        "        train_gan(generator, discriminator, gen_optimizer, dis_optimizer, selected_loader,\n",
        "                  valid_loader, num_epochs, metrics)\n",
        "test_fake(generator, discriminator, metrics)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 17] File exists: './augGAN'\n",
            "[Errno 17] File exists: './augGAN/model'\n",
            "[Errno 17] File exists: './augGAN/plots'\n",
            "[Errno 17] File exists: './augGAN/output_images'\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "GAN loaded for epochs:  300\n",
            "Generator(\n",
            "  (main): Sequential(\n",
            "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (13): Tanh()\n",
            "  )\n",
            ")\n",
            "Discriminator(\n",
            "  (main): Sequential(\n",
            "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (12): Sigmoid()\n",
            "  )\n",
            ")\n",
            "Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.5, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.0002\n",
            "    weight_decay: 0\n",
            ")\n",
            "Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.5, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.0002\n",
            "    weight_decay: 0\n",
            ")\n",
            "2020-08-06_18:26:13\n",
            "Testing Block.........\n",
            "Discriminator_mean:  0.14505085349082947\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8la1EFeB3zRF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "outputId": "e5f4578f-4ee0-4064-9200-418b92baffd5"
      },
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "summary(generator, (100, 1, 1))\n",
        "summary(discriminator, (1, 64, 64))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "   ConvTranspose2d-1            [-1, 512, 4, 4]         819,200\n",
            "       BatchNorm2d-2            [-1, 512, 4, 4]           1,024\n",
            "              ReLU-3            [-1, 512, 4, 4]               0\n",
            "   ConvTranspose2d-4            [-1, 256, 8, 8]       2,097,152\n",
            "       BatchNorm2d-5            [-1, 256, 8, 8]             512\n",
            "              ReLU-6            [-1, 256, 8, 8]               0\n",
            "   ConvTranspose2d-7          [-1, 128, 16, 16]         524,288\n",
            "       BatchNorm2d-8          [-1, 128, 16, 16]             256\n",
            "              ReLU-9          [-1, 128, 16, 16]               0\n",
            "  ConvTranspose2d-10           [-1, 64, 32, 32]         131,072\n",
            "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
            "             ReLU-12           [-1, 64, 32, 32]               0\n",
            "  ConvTranspose2d-13            [-1, 1, 64, 64]           1,024\n",
            "             Tanh-14            [-1, 1, 64, 64]               0\n",
            "================================================================\n",
            "Total params: 3,574,656\n",
            "Trainable params: 3,574,656\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 2.88\n",
            "Params size (MB): 13.64\n",
            "Estimated Total Size (MB): 16.51\n",
            "----------------------------------------------------------------\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,024\n",
            "         LeakyReLU-2           [-1, 64, 32, 32]               0\n",
            "            Conv2d-3          [-1, 128, 16, 16]         131,072\n",
            "       BatchNorm2d-4          [-1, 128, 16, 16]             256\n",
            "         LeakyReLU-5          [-1, 128, 16, 16]               0\n",
            "            Conv2d-6            [-1, 256, 8, 8]         524,288\n",
            "       BatchNorm2d-7            [-1, 256, 8, 8]             512\n",
            "         LeakyReLU-8            [-1, 256, 8, 8]               0\n",
            "            Conv2d-9            [-1, 512, 4, 4]       2,097,152\n",
            "      BatchNorm2d-10            [-1, 512, 4, 4]           1,024\n",
            "        LeakyReLU-11            [-1, 512, 4, 4]               0\n",
            "           Conv2d-12              [-1, 1, 1, 1]           8,192\n",
            "          Sigmoid-13              [-1, 1, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 2,763,520\n",
            "Trainable params: 2,763,520\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.02\n",
            "Forward/backward pass size (MB): 2.31\n",
            "Params size (MB): 10.54\n",
            "Estimated Total Size (MB): 12.87\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N0yiqHfzOzX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "38bef181-1e30-42e5-fc3e-a7007f61363e"
      },
      "source": [
        "print(generator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generator(\n",
            "  (main): Sequential(\n",
            "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (13): Tanh()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-Z61n2SAhlv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "16450b63-7c25-4849-c24e-a219560e9683"
      },
      "source": [
        "print(discriminator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Discriminator(\n",
            "  (main): Sequential(\n",
            "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (12): Sigmoid()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}